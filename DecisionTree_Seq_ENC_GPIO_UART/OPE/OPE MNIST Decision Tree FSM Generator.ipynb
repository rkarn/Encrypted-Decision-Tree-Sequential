{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data from yann lecunn dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yann Lecunn dataset is of the format idx and split across 4 files\n",
    "1. train-images.idx3-ubyte : training image set which consists of 60000 images each image is represented by a 28*28 array\n",
    "2. train-labels.idx1-ubyte : training label set which consists of 60000 labels \n",
    "3. t10k-images.idx3-ubyte : test image set which consists of 10000 images each image is represented by a 28*28\n",
    "4. t10k-labels.idx1-ubyte : training label set which consists of 10000 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import idx2numpy\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_3D = idx2numpy.convert_from_file('train-images.idx3-ubyte')\n",
    "X_train = X_train_3D.flatten().reshape(60000,784)\n",
    "\n",
    "y_train = idx2numpy.convert_from_file('train-labels.idx1-ubyte')\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_3D = idx2numpy.convert_from_file('t10k-images.idx3-ubyte')\n",
    "X_test =  X_test_3D.flatten().reshape(10000,784)\n",
    "\n",
    "y_test = idx2numpy.convert_from_file('t10k-labels.idx1-ubyte')\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=8)\n",
      "Number of nodes in the decision tree 505.\n",
      "Number of threshold in the decision tree 505.\n",
      "Number of leaves in the decision tree 253.\n",
      "0.8141 0.82696\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "X_shuffle,y_shuffle = shuffle(X_train,y_train)\n",
    "X_train = X_shuffle[0:50000]\n",
    "y_train = y_shuffle[0:50000]\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "#dt_clf = tree.DecisionTreeClassifier(max_depth=20, max_leaf_nodes=300)\n",
    "#dt_clf = tree.DecisionTreeClassifier(max_depth=4, max_leaf_nodes=20)\n",
    "dt_clf = tree.DecisionTreeClassifier(max_depth=8)\n",
    "\n",
    "#y_train_pred = cross_val_predict(dt_clf, X_train, y_train, cv=2)\n",
    "print(dt_clf.fit(X_train, y_train))\n",
    "\n",
    "print('Number of nodes in the decision tree {}.'.format(dt_clf.tree_.node_count))\n",
    "print('Number of threshold in the decision tree {}.'.format(len(dt_clf.tree_.threshold)))\n",
    "print('Number of leaves in the decision tree {}.'.format(dt_clf.tree_.n_leaves))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, dt_clf.predict(X_test)), accuracy_score(y_train, dt_clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max and Min values of thresholds in decision tree are 253 -2\n"
     ]
    }
   ],
   "source": [
    "threshold = dt_clf.tree_.threshold\n",
    "import pandas as pd\n",
    "df_train = pd.DataFrame(data = X_train, columns = range(X_train[0].shape[0]))\n",
    "df_test = pd.DataFrame(data = X_test, columns = range(X_test[0].shape[0]))\n",
    "df_train.shape, df_test.shape\n",
    "df = pd.concat([df_train, df_test])\n",
    "unique_vals = []\n",
    "for i in df.columns:\n",
    "    unique_vals.append(df[i].unique())\n",
    "flatten_list = np.concatenate(unique_vals).ravel()\n",
    "print('Max and Min values of thresholds in decision tree are', max([int(i) for i in list(set(threshold))]), min([int(i) for i in list(set(threshold))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Displaying the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_350 <= 131.50\n",
      "|   |--- feature_568 <= 0.50\n",
      "|   |   |--- feature_430 <= 0.50\n",
      "|   |   |   |--- feature_405 <= 16.50\n",
      "|   |   |   |   |--- feature_484 <= 0.50\n",
      "|   |   |   |   |   |--- feature_154 <= 0.50\n",
      "|   |   |   |   |   |   |--- feature_594 <= 21.50\n",
      "|   |   |   |   |   |   |   |--- feature_157 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_157 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_594 >  21.50\n",
      "|   |   |   |   |   |   |   |--- feature_302 <= 6.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_302 >  6.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_154 >  0.50\n",
      "|   |   |   |   |   |   |--- feature_509 <= 22.50\n",
      "|   |   |   |   |   |   |   |--- feature_544 <= 4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_544 >  4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_509 >  22.50\n",
      "|   |   |   |   |   |   |   |--- feature_323 <= 97.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_323 >  97.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- feature_484 >  0.50\n",
      "|   |   |   |   |   |--- feature_211 <= 9.50\n",
      "|   |   |   |   |   |   |--- feature_487 <= 135.50\n",
      "|   |   |   |   |   |   |   |--- feature_514 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_514 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_487 >  135.50\n",
      "|   |   |   |   |   |   |   |--- feature_294 <= 8.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_294 >  8.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |--- feature_211 >  9.50\n",
      "|   |   |   |   |   |   |--- feature_437 <= 1.00\n",
      "|   |   |   |   |   |   |   |--- feature_489 <= 9.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_489 >  9.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |--- feature_437 >  1.00\n",
      "|   |   |   |   |   |   |   |--- feature_427 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_427 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |--- feature_405 >  16.50\n",
      "|   |   |   |   |--- feature_516 <= 7.50\n",
      "|   |   |   |   |   |--- feature_353 <= 1.00\n",
      "|   |   |   |   |   |   |--- feature_322 <= 6.50\n",
      "|   |   |   |   |   |   |   |--- feature_355 <= 12.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_355 >  12.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_322 >  6.50\n",
      "|   |   |   |   |   |   |   |--- feature_546 <= 2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_546 >  2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |--- feature_353 >  1.00\n",
      "|   |   |   |   |   |   |--- feature_346 <= 1.00\n",
      "|   |   |   |   |   |   |   |--- feature_181 <= 18.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_181 >  18.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_346 >  1.00\n",
      "|   |   |   |   |   |   |   |--- feature_210 <= 22.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_210 >  22.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |--- feature_516 >  7.50\n",
      "|   |   |   |   |   |--- feature_376 <= 3.50\n",
      "|   |   |   |   |   |   |--- feature_207 <= 1.00\n",
      "|   |   |   |   |   |   |   |--- feature_264 <= 92.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_264 >  92.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |--- feature_207 >  1.00\n",
      "|   |   |   |   |   |   |   |--- feature_484 <= 6.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_484 >  6.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |--- feature_376 >  3.50\n",
      "|   |   |   |   |   |   |--- feature_658 <= 6.50\n",
      "|   |   |   |   |   |   |   |--- feature_127 <= 14.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_127 >  14.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_658 >  6.50\n",
      "|   |   |   |   |   |   |   |--- feature_434 <= 87.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_434 >  87.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |--- feature_430 >  0.50\n",
      "|   |   |   |--- feature_211 <= 27.50\n",
      "|   |   |   |   |--- feature_98 <= 0.50\n",
      "|   |   |   |   |   |--- feature_267 <= 121.50\n",
      "|   |   |   |   |   |   |--- feature_95 <= 7.00\n",
      "|   |   |   |   |   |   |   |--- feature_155 <= 78.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_155 >  78.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_95 >  7.00\n",
      "|   |   |   |   |   |   |   |--- feature_242 <= 104.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_242 >  104.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- feature_267 >  121.50\n",
      "|   |   |   |   |   |   |--- feature_353 <= 1.00\n",
      "|   |   |   |   |   |   |   |--- feature_411 <= 114.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_411 >  114.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |--- feature_353 >  1.00\n",
      "|   |   |   |   |   |   |   |--- feature_432 <= 12.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_432 >  12.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |--- feature_98 >  0.50\n",
      "|   |   |   |   |   |--- feature_242 <= 44.50\n",
      "|   |   |   |   |   |   |--- feature_272 <= 192.00\n",
      "|   |   |   |   |   |   |   |--- feature_627 <= 253.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_627 >  253.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_272 >  192.00\n",
      "|   |   |   |   |   |   |   |--- feature_512 <= 133.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_512 >  133.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- feature_242 >  44.50\n",
      "|   |   |   |   |   |   |--- feature_263 <= 65.00\n",
      "|   |   |   |   |   |   |   |--- feature_98 <= 23.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_98 >  23.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_263 >  65.00\n",
      "|   |   |   |   |   |   |   |--- feature_459 <= 168.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_459 >  168.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |--- feature_211 >  27.50\n",
      "|   |   |   |   |--- feature_156 <= 0.50\n",
      "|   |   |   |   |   |--- feature_381 <= 3.50\n",
      "|   |   |   |   |   |   |--- feature_217 <= 29.50\n",
      "|   |   |   |   |   |   |   |--- feature_542 <= 70.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_542 >  70.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_217 >  29.50\n",
      "|   |   |   |   |   |   |   |--- feature_358 <= 9.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_358 >  9.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_381 >  3.50\n",
      "|   |   |   |   |   |   |--- feature_154 <= 2.50\n",
      "|   |   |   |   |   |   |   |--- feature_442 <= 6.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_442 >  6.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |--- feature_154 >  2.50\n",
      "|   |   |   |   |   |   |   |--- feature_292 <= 82.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_292 >  82.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |--- feature_156 >  0.50\n",
      "|   |   |   |   |   |--- feature_101 <= 1.00\n",
      "|   |   |   |   |   |   |--- feature_656 <= 1.00\n",
      "|   |   |   |   |   |   |   |--- feature_572 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_572 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_656 >  1.00\n",
      "|   |   |   |   |   |   |   |--- feature_434 <= 7.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_434 >  7.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |--- feature_101 >  1.00\n",
      "|   |   |   |   |   |   |--- feature_271 <= 153.50\n",
      "|   |   |   |   |   |   |   |--- feature_571 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_571 >  1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_271 >  153.50\n",
      "|   |   |   |   |   |   |   |--- feature_489 <= 6.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_489 >  6.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |--- feature_568 >  0.50\n",
      "|   |   |--- feature_435 <= 0.50\n",
      "|   |   |   |--- feature_489 <= 22.50\n",
      "|   |   |   |   |--- feature_351 <= 12.50\n",
      "|   |   |   |   |   |--- feature_214 <= 0.50\n",
      "|   |   |   |   |   |   |--- feature_436 <= 2.50\n",
      "|   |   |   |   |   |   |   |--- feature_455 <= 18.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_455 >  18.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_436 >  2.50\n",
      "|   |   |   |   |   |   |   |--- feature_540 <= 58.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_540 >  58.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |--- feature_214 >  0.50\n",
      "|   |   |   |   |   |   |--- feature_379 <= 115.50\n",
      "|   |   |   |   |   |   |   |--- feature_516 <= 203.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_516 >  203.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_379 >  115.50\n",
      "|   |   |   |   |   |   |   |--- feature_216 <= 35.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_216 >  35.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |--- feature_351 >  12.50\n",
      "|   |   |   |   |   |--- feature_301 <= 6.50\n",
      "|   |   |   |   |   |   |--- feature_485 <= 59.00\n",
      "|   |   |   |   |   |   |   |--- feature_352 <= 248.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_352 >  248.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_485 >  59.00\n",
      "|   |   |   |   |   |   |   |--- feature_297 <= 2.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_297 >  2.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_301 >  6.50\n",
      "|   |   |   |   |   |   |--- feature_378 <= 42.50\n",
      "|   |   |   |   |   |   |   |--- feature_238 <= 14.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_238 >  14.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_378 >  42.50\n",
      "|   |   |   |   |   |   |   |--- feature_294 <= 68.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_294 >  68.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |--- feature_489 >  22.50\n",
      "|   |   |   |   |--- feature_320 <= 1.00\n",
      "|   |   |   |   |   |--- feature_344 <= 84.00\n",
      "|   |   |   |   |   |   |--- feature_351 <= 5.00\n",
      "|   |   |   |   |   |   |   |--- feature_376 <= 62.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_376 >  62.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- feature_351 >  5.00\n",
      "|   |   |   |   |   |   |   |--- feature_402 <= 48.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_402 >  48.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_344 >  84.00\n",
      "|   |   |   |   |   |   |--- feature_192 <= 48.50\n",
      "|   |   |   |   |   |   |   |--- feature_599 <= 30.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_599 >  30.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_192 >  48.50\n",
      "|   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |--- feature_320 >  1.00\n",
      "|   |   |   |   |   |--- feature_385 <= 18.50\n",
      "|   |   |   |   |   |   |--- feature_513 <= 71.00\n",
      "|   |   |   |   |   |   |   |--- feature_582 <= 16.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_582 >  16.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_513 >  71.00\n",
      "|   |   |   |   |   |   |   |--- feature_405 <= 225.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_405 >  225.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_385 >  18.50\n",
      "|   |   |   |   |   |   |--- feature_400 <= 51.50\n",
      "|   |   |   |   |   |   |   |--- feature_404 <= 1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_404 >  1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_400 >  51.50\n",
      "|   |   |   |   |   |   |   |--- feature_378 <= 22.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_378 >  22.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |--- feature_435 >  0.50\n",
      "|   |   |   |--- feature_346 <= 0.50\n",
      "|   |   |   |   |--- feature_348 <= 78.50\n",
      "|   |   |   |   |   |--- feature_343 <= 36.50\n",
      "|   |   |   |   |   |   |--- feature_155 <= 0.50\n",
      "|   |   |   |   |   |   |   |--- feature_652 <= 6.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_652 >  6.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_155 >  0.50\n",
      "|   |   |   |   |   |   |   |--- feature_517 <= 8.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_517 >  8.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |--- feature_343 >  36.50\n",
      "|   |   |   |   |   |   |--- feature_213 <= 1.50\n",
      "|   |   |   |   |   |   |   |--- feature_574 <= 16.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_574 >  16.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_213 >  1.50\n",
      "|   |   |   |   |   |   |   |--- feature_401 <= 31.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_401 >  31.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |--- feature_348 >  78.50\n",
      "|   |   |   |   |   |--- feature_353 <= 1.00\n",
      "|   |   |   |   |   |   |--- feature_485 <= 94.00\n",
      "|   |   |   |   |   |   |   |--- feature_383 <= 5.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_383 >  5.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_485 >  94.00\n",
      "|   |   |   |   |   |   |   |--- feature_130 <= 17.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_130 >  17.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |--- feature_353 >  1.00\n",
      "|   |   |   |   |   |   |--- feature_466 <= 47.50\n",
      "|   |   |   |   |   |   |   |--- feature_405 <= 110.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_405 >  110.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_466 >  47.50\n",
      "|   |   |   |   |   |   |   |--- feature_242 <= 5.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_242 >  5.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |--- feature_346 >  0.50\n",
      "|   |   |   |   |--- feature_655 <= 0.50\n",
      "|   |   |   |   |   |--- feature_271 <= 1.00\n",
      "|   |   |   |   |   |   |--- feature_484 <= 0.50\n",
      "|   |   |   |   |   |   |   |--- feature_489 <= 14.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_489 >  14.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_484 >  0.50\n",
      "|   |   |   |   |   |   |   |--- feature_219 <= 2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_219 >  2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |--- feature_271 >  1.00\n",
      "|   |   |   |   |   |   |--- feature_354 <= 3.50\n",
      "|   |   |   |   |   |   |   |--- feature_357 <= 4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_357 >  4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_354 >  3.50\n",
      "|   |   |   |   |   |   |   |--- feature_156 <= 14.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_156 >  14.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |--- feature_655 >  0.50\n",
      "|   |   |   |   |   |--- feature_354 <= 0.50\n",
      "|   |   |   |   |   |   |--- feature_514 <= 44.50\n",
      "|   |   |   |   |   |   |   |--- feature_357 <= 9.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_357 >  9.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_514 >  44.50\n",
      "|   |   |   |   |   |   |   |--- feature_384 <= 162.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_384 >  162.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_354 >  0.50\n",
      "|   |   |   |   |   |   |--- feature_434 <= 41.00\n",
      "|   |   |   |   |   |   |   |--- feature_456 <= 43.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_456 >  43.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_434 >  41.00\n",
      "|   |   |   |   |   |   |   |--- feature_514 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_514 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|--- feature_350 >  131.50\n",
      "|   |--- feature_489 <= 26.50\n",
      "|   |   |--- feature_290 <= 34.50\n",
      "|   |   |   |--- feature_486 <= 101.50\n",
      "|   |   |   |   |--- feature_296 <= 2.50\n",
      "|   |   |   |   |   |--- feature_490 <= 87.50\n",
      "|   |   |   |   |   |   |--- feature_315 <= 19.50\n",
      "|   |   |   |   |   |   |   |--- feature_177 <= 1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_177 >  1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_315 >  19.50\n",
      "|   |   |   |   |   |   |   |--- feature_299 <= 2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_299 >  2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- feature_490 >  87.50\n",
      "|   |   |   |   |   |   |--- feature_627 <= 4.00\n",
      "|   |   |   |   |   |   |   |--- feature_403 <= 31.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_403 >  31.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- feature_627 >  4.00\n",
      "|   |   |   |   |   |   |   |--- feature_382 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_382 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |--- feature_296 >  2.50\n",
      "|   |   |   |   |   |--- feature_153 <= 0.50\n",
      "|   |   |   |   |   |   |--- feature_208 <= 53.50\n",
      "|   |   |   |   |   |   |   |--- feature_386 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_386 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_208 >  53.50\n",
      "|   |   |   |   |   |   |   |--- feature_316 <= 88.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_316 >  88.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |--- feature_153 >  0.50\n",
      "|   |   |   |   |   |   |--- feature_488 <= 60.50\n",
      "|   |   |   |   |   |   |   |--- feature_315 <= 138.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_315 >  138.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_488 >  60.50\n",
      "|   |   |   |   |   |   |   |--- feature_467 <= 179.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_467 >  179.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |--- feature_486 >  101.50\n",
      "|   |   |   |   |--- feature_656 <= 0.50\n",
      "|   |   |   |   |   |--- feature_152 <= 6.00\n",
      "|   |   |   |   |   |   |--- feature_601 <= 87.50\n",
      "|   |   |   |   |   |   |   |--- feature_161 <= 46.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_161 >  46.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_601 >  87.50\n",
      "|   |   |   |   |   |   |   |--- feature_271 <= 2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_271 >  2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_152 >  6.00\n",
      "|   |   |   |   |   |   |--- feature_465 <= 16.00\n",
      "|   |   |   |   |   |   |   |--- feature_343 <= 23.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_343 >  23.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_465 >  16.00\n",
      "|   |   |   |   |   |   |   |--- feature_431 <= 41.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_431 >  41.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |--- feature_656 >  0.50\n",
      "|   |   |   |   |   |--- feature_435 <= 79.00\n",
      "|   |   |   |   |   |   |--- feature_352 <= 2.50\n",
      "|   |   |   |   |   |   |   |--- feature_243 <= 18.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_243 >  18.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_352 >  2.50\n",
      "|   |   |   |   |   |   |   |--- feature_410 <= 2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_410 >  2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_435 >  79.00\n",
      "|   |   |   |   |   |   |--- feature_550 <= 234.00\n",
      "|   |   |   |   |   |   |   |--- feature_439 <= 251.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_439 >  251.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_550 >  234.00\n",
      "|   |   |   |   |   |   |   |--- feature_292 <= 96.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_292 >  96.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |--- feature_290 >  34.50\n",
      "|   |   |   |--- feature_297 <= 7.50\n",
      "|   |   |   |   |--- feature_486 <= 58.00\n",
      "|   |   |   |   |   |--- feature_186 <= 2.50\n",
      "|   |   |   |   |   |   |--- feature_293 <= 214.50\n",
      "|   |   |   |   |   |   |   |--- feature_328 <= 6.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_328 >  6.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_293 >  214.50\n",
      "|   |   |   |   |   |   |   |--- feature_463 <= 183.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_463 >  183.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_186 >  2.50\n",
      "|   |   |   |   |   |   |--- feature_301 <= 78.50\n",
      "|   |   |   |   |   |   |   |--- feature_295 <= 226.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_295 >  226.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_301 >  78.50\n",
      "|   |   |   |   |   |   |   |--- feature_381 <= 7.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_381 >  7.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |--- feature_486 >  58.00\n",
      "|   |   |   |   |   |--- feature_656 <= 7.50\n",
      "|   |   |   |   |   |   |--- feature_430 <= 84.00\n",
      "|   |   |   |   |   |   |   |--- feature_319 <= 246.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_319 >  246.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- feature_430 >  84.00\n",
      "|   |   |   |   |   |   |   |--- feature_571 <= 3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_571 >  3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |--- feature_656 >  7.50\n",
      "|   |   |   |   |   |   |--- feature_300 <= 5.50\n",
      "|   |   |   |   |   |   |   |--- feature_294 <= 134.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_294 >  134.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_300 >  5.50\n",
      "|   |   |   |   |   |   |   |--- feature_407 <= 90.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_407 >  90.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |--- feature_297 >  7.50\n",
      "|   |   |   |   |--- feature_598 <= 0.50\n",
      "|   |   |   |   |   |--- feature_210 <= 5.00\n",
      "|   |   |   |   |   |   |--- feature_321 <= 222.00\n",
      "|   |   |   |   |   |   |   |--- feature_408 <= 168.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_408 >  168.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_321 >  222.00\n",
      "|   |   |   |   |   |   |   |--- feature_404 <= 110.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_404 >  110.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- feature_210 >  5.00\n",
      "|   |   |   |   |   |   |--- feature_652 <= 3.50\n",
      "|   |   |   |   |   |   |   |--- feature_154 <= 46.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_154 >  46.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_652 >  3.50\n",
      "|   |   |   |   |   |   |   |--- feature_513 <= 150.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_513 >  150.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |--- feature_598 >  0.50\n",
      "|   |   |   |   |   |--- feature_486 <= 9.50\n",
      "|   |   |   |   |   |   |--- feature_427 <= 168.50\n",
      "|   |   |   |   |   |   |   |--- feature_318 <= 78.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_318 >  78.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- feature_427 >  168.50\n",
      "|   |   |   |   |   |   |   |--- feature_380 <= 224.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_380 >  224.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |--- feature_486 >  9.50\n",
      "|   |   |   |   |   |   |--- feature_400 <= 20.00\n",
      "|   |   |   |   |   |   |   |--- feature_545 <= 53.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_545 >  53.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_400 >  20.00\n",
      "|   |   |   |   |   |   |   |--- feature_242 <= 5.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_242 >  5.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |--- feature_489 >  26.50\n",
      "|   |   |--- feature_234 <= 0.50\n",
      "|   |   |   |--- feature_402 <= 0.50\n",
      "|   |   |   |   |--- feature_300 <= 20.00\n",
      "|   |   |   |   |   |--- feature_149 <= 4.50\n",
      "|   |   |   |   |   |   |--- feature_466 <= 2.50\n",
      "|   |   |   |   |   |   |   |--- feature_538 <= 26.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_538 >  26.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- feature_466 >  2.50\n",
      "|   |   |   |   |   |   |   |--- feature_404 <= 248.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_404 >  248.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |--- feature_149 >  4.50\n",
      "|   |   |   |   |   |   |--- feature_318 <= 13.50\n",
      "|   |   |   |   |   |   |   |--- feature_543 <= 20.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_543 >  20.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_318 >  13.50\n",
      "|   |   |   |   |   |   |   |--- feature_434 <= 35.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_434 >  35.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |--- feature_300 >  20.00\n",
      "|   |   |   |   |   |--- feature_265 <= 1.50\n",
      "|   |   |   |   |   |   |--- feature_624 <= 0.50\n",
      "|   |   |   |   |   |   |   |--- feature_120 <= 5.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_120 >  5.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_624 >  0.50\n",
      "|   |   |   |   |   |   |   |--- feature_183 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_183 >  1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |--- feature_265 >  1.50\n",
      "|   |   |   |   |   |   |--- feature_514 <= 14.00\n",
      "|   |   |   |   |   |   |   |--- feature_212 <= 109.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_212 >  109.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |--- feature_514 >  14.00\n",
      "|   |   |   |   |   |   |   |--- feature_454 <= 8.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_454 >  8.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |--- feature_402 >  0.50\n",
      "|   |   |   |   |--- feature_103 <= 1.50\n",
      "|   |   |   |   |   |--- feature_276 <= 8.50\n",
      "|   |   |   |   |   |   |--- feature_712 <= 3.00\n",
      "|   |   |   |   |   |   |   |--- feature_657 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_657 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_712 >  3.00\n",
      "|   |   |   |   |   |   |   |--- feature_212 <= 70.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_212 >  70.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |--- feature_276 >  8.50\n",
      "|   |   |   |   |   |   |--- feature_381 <= 124.00\n",
      "|   |   |   |   |   |   |   |--- feature_374 <= 3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_374 >  3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- feature_381 >  124.00\n",
      "|   |   |   |   |   |   |   |--- feature_211 <= 16.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_211 >  16.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |--- feature_103 >  1.50\n",
      "|   |   |   |   |   |--- feature_271 <= 17.00\n",
      "|   |   |   |   |   |   |--- feature_398 <= 156.00\n",
      "|   |   |   |   |   |   |   |--- feature_152 <= 4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_152 >  4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_398 >  156.00\n",
      "|   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |--- feature_271 >  17.00\n",
      "|   |   |   |   |   |   |--- feature_320 <= 179.50\n",
      "|   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_320 >  179.50\n",
      "|   |   |   |   |   |   |   |--- feature_412 <= 252.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_412 >  252.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_234 >  0.50\n",
      "|   |   |   |--- feature_658 <= 2.50\n",
      "|   |   |   |   |--- feature_345 <= 18.00\n",
      "|   |   |   |   |   |--- feature_526 <= 1.00\n",
      "|   |   |   |   |   |   |--- feature_514 <= 166.00\n",
      "|   |   |   |   |   |   |   |--- feature_603 <= 205.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_603 >  205.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_514 >  166.00\n",
      "|   |   |   |   |   |   |   |--- feature_320 <= 164.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_320 >  164.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_526 >  1.00\n",
      "|   |   |   |   |   |   |--- feature_370 <= 11.50\n",
      "|   |   |   |   |   |   |   |--- feature_284 <= 22.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_284 >  22.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_370 >  11.50\n",
      "|   |   |   |   |   |   |   |--- feature_151 <= 71.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_151 >  71.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |--- feature_345 >  18.00\n",
      "|   |   |   |   |   |--- feature_575 <= 231.50\n",
      "|   |   |   |   |   |   |--- feature_211 <= 108.50\n",
      "|   |   |   |   |   |   |   |--- feature_408 <= 113.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_408 >  113.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_211 >  108.50\n",
      "|   |   |   |   |   |   |   |--- feature_541 <= 97.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_541 >  97.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |--- feature_575 >  231.50\n",
      "|   |   |   |   |   |   |--- feature_239 <= 110.50\n",
      "|   |   |   |   |   |   |   |--- feature_187 <= 57.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_187 >  57.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_239 >  110.50\n",
      "|   |   |   |   |   |   |   |--- feature_453 <= 198.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_453 >  198.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_658 >  2.50\n",
      "|   |   |   |   |--- feature_515 <= 59.00\n",
      "|   |   |   |   |   |--- feature_545 <= 5.50\n",
      "|   |   |   |   |   |   |--- feature_318 <= 93.50\n",
      "|   |   |   |   |   |   |   |--- feature_546 <= 159.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_546 >  159.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_318 >  93.50\n",
      "|   |   |   |   |   |   |   |--- feature_485 <= 119.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_485 >  119.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_545 >  5.50\n",
      "|   |   |   |   |   |   |--- feature_578 <= 21.00\n",
      "|   |   |   |   |   |   |   |--- feature_346 <= 52.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_346 >  52.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |--- feature_578 >  21.00\n",
      "|   |   |   |   |   |   |   |--- feature_575 <= 213.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_575 >  213.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- feature_515 >  59.00\n",
      "|   |   |   |   |   |--- feature_319 <= 0.50\n",
      "|   |   |   |   |   |   |--- feature_344 <= 126.00\n",
      "|   |   |   |   |   |   |   |--- feature_608 <= 4.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_608 >  4.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_344 >  126.00\n",
      "|   |   |   |   |   |   |   |--- feature_122 <= 5.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_122 >  5.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |--- feature_319 >  0.50\n",
      "|   |   |   |   |   |   |--- feature_440 <= 77.50\n",
      "|   |   |   |   |   |   |   |--- feature_609 <= 209.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_609 >  209.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_440 >  77.50\n",
      "|   |   |   |   |   |   |   |--- feature_547 <= 14.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_547 >  14.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      " [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_text\n",
    "text_representation = export_text(dt_clf)\n",
    "print(text_representation, dt_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential: New FSM Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    \n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print (\"{}{}:if ({} <= {})\".format(indent, node, name, int(round(threshold,3)))) \n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print (\"{}{}:else \".format(indent, node, name, int(round(threshold,3))))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print (\"{} Label<={};\".format(indent, np.argmax(tree_.value[node][0],axis=0)))\n",
    "\n",
    "    recurse(0, 1)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['pixels[{}]'.format(str(i)) for i in cols]\n",
    "class_names = [str(i) for i in dt_clf.classes_]\n",
    "tree_to_code(dt_clf, features)\n",
    "\n",
    "with open('verilog_newFSM.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "def write_file(data_towrite):\n",
    "    with open('verilog_file.v', 'a', encoding='utf-8') as file:\n",
    "        file.writelines(data_towrite)\n",
    "        file.close()\n",
    "        \n",
    "def write_line_file(data_towrite, line_num):\n",
    "    with open('verilog_file.v', 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    file_content[line_num] = file_content[line_num].replace('\\n','') + ' ' + data_towrite + '\\n'  \n",
    "    with open('verilog_file.v', 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "        \n",
    "def search_content_file(word):\n",
    "    with open('verilog_file.v', 'r') as file:\n",
    "        file_content = file.readlines()\n",
    "        for line_num,line in enumerate(file_content):\n",
    "            if word in line:\n",
    "                return(line_num)\n",
    "        return(\"content doesn't exists.\")\n",
    "    \n",
    "def update_stateformat_file():\n",
    "    with open('verilog_file.v', 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    for line_num,line in enumerate(file_content):\n",
    "        if 'if' in line:\n",
    "            file_content[line_num] = '16\\'d' + file_content[line_num].strip() + ' \\n'  \n",
    "    with open('verilog_file.v', 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "        \n",
    "def clear_file():\n",
    "    with open('verilog_file.v', 'w', encoding='utf-8') as file:\n",
    "        pass\n",
    "        file.close()\n",
    "\n",
    "import itertools\n",
    "with open('verilog_newFSM.txt', 'r') as f:\n",
    "    tree_verilog = f.read()\n",
    "    f.close()\n",
    "\n",
    "clear_file()\n",
    "line_num = 0\n",
    "else_state = 0\n",
    "else_nextif_state = 0\n",
    "curr_line,next_line = itertools.tee(tree_verilog.split('\\n'))\n",
    "next(next_line, None)\n",
    "for i,j in list(zip(curr_line,next_line)):\n",
    "    if 'Label' in i:\n",
    "        pass\n",
    "        #write_file(f'  begin {i.strip()} state<=0;ml_inference_completed<=1; end \\n')\n",
    "    elif 'else' in i and 'Label' in j:\n",
    "        else_state = i.strip().split(':')[0]\n",
    "        line_num = search_content_file(' '+str(else_state)+':if' )\n",
    "        write_line_file(f'\\n       else begin {j.strip()} state<=0;ml_inference_completed<=1; end ', line_num)\n",
    "        #write_file(f'   {i.strip().split(\":\")[-1]} ')\n",
    "    elif 'else' in i and 'if' in j:\n",
    "        else_state = i.strip().split(':')[0]\n",
    "        else_nextif_state = j.strip().split(':')[0]\n",
    "        line_num = search_content_file(' '+str(else_state)+':if' )\n",
    "        write_line_file(f'else begin state<={else_nextif_state}; end ', line_num)\n",
    "    elif 'if' in i and 'Label' in j:\n",
    "        write_file(f'\\n {i.strip()} begin {j.strip()} state<=0;ml_inference_completed<=1; end ')\n",
    "    elif 'if' in i and 'if' in j:\n",
    "        write_file(f'\\n {i.strip()} begin state<={j.strip().split(\":\")[0]}; end \\n ')  \n",
    "update_stateformat_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the number of \"if\", \"else\" and \"Label\" in verilog with decision tree architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of \"if\" statements 252.\n",
      "Number of \"else\" statements 252.\n",
      "Number of \"label\" statements 253.\n"
     ]
    }
   ],
   "source": [
    "#verifying that the number of \"if\" statements is one less than the number of nodes.\n",
    "file1 = open('verilog_file.v', 'r')\n",
    "contents = file1.readlines()\n",
    "counter_if =0\n",
    "for line in contents:\n",
    "    if 'if' in line:\n",
    "        counter_if = counter_if+1\n",
    "print('Number of \"if\" statements {}.'.format(counter_if))\n",
    "\n",
    "#verifying that the number of \"else\" statements is one less than the number of leaves.\n",
    "file1 = open('verilog_file.v', 'r')\n",
    "contents = file1.readlines()\n",
    "counter_else =0\n",
    "for line in contents:\n",
    "    if 'else' in line:\n",
    "        counter_else = counter_else+1\n",
    "print('Number of \"else\" statements {}.'.format(counter_else))\n",
    "\n",
    "#verifying that the number of \"Label\" statements is equal to the number of leaves.\n",
    "file1 = open('verilog_file.v', 'r')\n",
    "contents = file1.readlines()\n",
    "counter_return =0\n",
    "for line in contents:\n",
    "    if 'Label' in line:\n",
    "        counter_return = counter_return+1\n",
    "print('Number of \"label\" statements {}.'.format(counter_return))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the tree into the source code by rounding the threshold to nearest integer and save it in a txt file. This is performed to verify the accuracy by using this dumped decision rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "#https://towardsdatascience.com/scikit-learn-decision-trees-explained-803f3812290d\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    print (\"def decision_tree_inference({}):\".format('feature_set'))\n",
    "    for i,pixel in enumerate(feature_names):\n",
    "            print (\"{}{}\".format(\"  \", pixel+'='+'feature_set['+str(i)+']'))\n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print (\"{}if {} <= {}:\".format(indent, name, int(round(threshold,3))))  #convert the threshold to integer\n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print (\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print (\"{}return {}\".format(indent, np.argmax(tree_.value[node][0],axis=0)))\n",
    "\n",
    "    recurse(0, 1)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['pixel'+str(i) for i in cols]\n",
    "class_names = [str(i) for i in dt_clf.classes_]\n",
    "tree_to_code(dt_clf, features)\n",
    "\n",
    "with open('mnist_decision_tree_inference.py', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8141 0.82696\n"
     ]
    }
   ],
   "source": [
    "from mnist_decision_tree_inference import decision_tree_inference\n",
    "y_test_pred_tree = []\n",
    "for i,test_samples in enumerate(X_test):\n",
    "    y_test_pred_tree.append(decision_tree_inference(test_samples))\n",
    "\n",
    "y_train_pred_tree = []\n",
    "for i,test_samples in enumerate(X_train):\n",
    "    y_train_pred_tree.append(decision_tree_inference(test_samples))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_test_pred_tree), accuracy_score(y_train, y_train_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPE Encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value of threshold = -2. Max value of threshold = 253\n",
      "Unique values in thresholds are:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 29, 30, 31, 34, 35, 36, 41, 42, 43, 44, 46, 47, 48, 51, 52, 53, 57, 58, 59, 60, 62, 65, 68, 70, 71, 77, 78, 79, 82, 84, 87, 88, 90, 92, 93, 94, 96, 97, 101, 104, 108, 109, 110, 113, 114, 115, 119, 121, 124, 126, 131, 133, 134, 135, 138, 150, 153, 156, 159, 162, 164, 166, 168, 179, 183, 192, 198, 203, 205, 209, 213, 214, 222, 224, 225, 226, 231, 234, 246, 248, 251, 252, 253, -2]\n",
      "Yes, ciphers are sorted. OPE valid.\n"
     ]
    }
   ],
   "source": [
    "#OPE_ciphers = {0: 12066, 1: 169498, 2: 226543, 3: 672042, 4: 838658, 5: 919684, 6: 977270, 7: 1055701, 8: 1058312, 9: 1087796, 10: 1097445, 11: 1176451, 12: 1183921, 13: 1220952, 14: 1557525, 15: 1727241, 16: 1892922, 17: 1960170, 18: 1966351, 19: 2025917, 20: 2086019, 21: 2186547, 22: 2240207, 23: 2247658, 24: 2262361, 25: 2322390, 26: 2400481, 27: 2456156, 28: 2492957, 29: 2566854, 30: 2641406, 31: 2654827, 32: 2657422, 33: 2673702, 34: 2710579, 35: 2896614, 36: 2970776, 37: 3006623, 38: 3015638, 39: 3041948, 40: 3127827, 41: 3150608, 42: 3187553, 43: 3216337, 44: 3344121, 45: 3442649, 46: 3511024, 47: 3594918, 48: 3655763, 49: 3672413, 50: 4035862, 51: 4081037, 52: 4104042, 53: 4152186, 54: 4163483, 55: 4180647, 56: 4246894, 57: 4351195, 58: 4429184, 59: 4549356, 60: 4607063, 61: 4639927, 62: 4782698, 63: 4788482, 64: 4837431, 65: 4864153, 66: 5118423, 67: 5261392, 68: 5299828, 69: 5367820, 70: 5389522, 71: 5404390, 72: 5440993, 73: 5521457, 74: 5571806, 75: 5576710, 76: 5603955, 77: 5623693, 78: 5687500, 79: 5784075, 80: 5801917, 81: 5815677, 82: 5860302, 83: 5895894, 84: 5910480, 85: 5962880, 86: 5987354, 87: 6025885, 88: 6031446, 89: 6045911, 90: 6214893, 91: 6269128, 92: 6320478, 93: 6325746, 94: 6358493, 95: 6382120, 96: 6414249, 97: 6469510, 98: 6517938, 99: 6553015, 100: 6586802, 101: 6657083, 102: 6766826, 103: 6824707, 104: 6851836, 105: 6887293, 106: 6901880, 107: 6922412, 108: 6945741, 109: 7088186, 110: 7169022, 111: 7387426, 112: 7498208, 113: 7574683, 114: 7877256, 115: 7990376, 116: 8014774, 117: 8247426, 118: 8310828, 119: 8348065, 120: 8420586, 121: 8447951, 122: 8484928, 123: 8573440, 124: 8592862, 125: 8606928, 126: 8675181, 127: 8693099, 128: 8800638, 129: 8817217, 130: 8874431, 131: 8883869, 132: 8920338, 133: 8942168, 134: 8959790, 135: 8966065, 136: 9099182, 137: 9115343, 138: 9201113, 139: 9268521, 140: 9307567, 141: 9345791, 142: 9375555, 143: 9377486, 144: 9394318, 145: 9398866, 146: 9458713, 147: 9541748, 148: 9619426, 149: 9676186, 150: 9715339, 151: 9757607, 152: 9804769, 153: 9857918, 154: 9891099, 155: 9903648, 156: 10010619, 157: 10038400, 158: 10138825, 159: 10168981, 160: 10275301, 161: 10385488, 162: 10486337, 163: 10487008, 164: 10620586, 165: 10655005, 166: 10680653, 167: 10694574, 168: 10724530, 169: 10779532, 170: 10828196, 171: 10830169, 172: 10848005, 173: 10876729, 174: 10926801, 175: 10954040, 176: 10976026, 177: 10977614, 178: 11056348, 179: 11250015, 180: 11302657, 181: 11315752, 182: 11460622, 183: 11536965, 184: 11572194, 185: 11677613, 186: 11698564, 187: 11743495, 188: 11783171, 189: 11911512, 190: 11937653, 191: 11947496, 192: 11976429, 193: 12012962, 194: 12031102, 195: 12109032, 196: 12238082, 197: 12280297, 198: 12295705, 199: 12377556, 200: 12388676, 201: 12476849, 202: 12502820, 203: 12576668, 204: 12630390, 205: 12698018, 206: 12724395, 207: 12777658, 208: 12876195, 209: 12960605, 210: 12993132, 211: 13034518, 212: 13225130, 213: 13251178, 214: 13278072, 215: 13425223, 216: 13577682, 217: 13650047, 218: 13760126, 219: 13867767, 220: 13949008, 221: 14074481, 222: 14138661, 223: 14156903, 224: 14327531, 225: 14364236, 226: 14391815, 227: 14533063, 228: 14584445, 229: 14692083, 230: 14727026, 231: 14785119, 232: 14850983, 233: 14965647, 234: 15038435, 235: 15059755, 236: 15207521, 237: 15280679, 238: 15305829, 239: 15337248, 240: 15415187, 241: 15423422, 242: 15551713, 243: 15791922, 244: 15802191, 245: 15861718, 246: 16000222, 247: 16069522, 248: 16267485, 249: 16306400, 250: 16537043, 251: 16637700, 252: 16730424, 253: 17031859, 254: 17167896, 255: 17228611}\n",
    "import pdb\n",
    "unique_thresholds = list(set([int(round(i,3)) for i in threshold]))\n",
    "print(f'Min value of threshold = {min(unique_thresholds)}. Max value of threshold = {max(unique_thresholds)}')\n",
    "print('Unique values in thresholds are: ', unique_thresholds)\n",
    "from pyope.ope import OPE, ValueRange\n",
    "#random_key = OPE.generate_key()\n",
    "cipher = OPE(b'long key' * 2, in_range=ValueRange(-100, 1000),\n",
    "                              out_range=ValueRange(0, 100000000))\n",
    "OPE_ciphers = {}\n",
    "all_plaintexts = list( set(unique_thresholds).union(set(range(256))) ) #Taking all the thresholds and pixels values\n",
    "all_plaintexts.sort()\n",
    "for i in all_plaintexts:\n",
    "    OPE_ciphers[i] = cipher.encrypt(i)\n",
    "\n",
    "    \n",
    "flag = 0\n",
    "ciphers_indecimal_copy = list(OPE_ciphers.values())[:]\n",
    "ciphers_indecimal_copy.sort()\n",
    "if (ciphers_indecimal_copy == list(OPE_ciphers.values())):\n",
    "    flag = 1\n",
    "     \n",
    "# printing result\n",
    "if (flag) :\n",
    "    print (\"Yes, ciphers are sorted. OPE valid.\")\n",
    "else :\n",
    "    print (\"No, ciphers are not sorted. OPE invalid.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Display\n",
      " In string: PPu3WGQj3+gyfEsARIJWA19oseVph2qjQ0Ok19K3b6Q= \n",
      " In Hex: 30547864764539542b743861714361316c754e43316754743575544a4c6f54324442723467462b6446736f3d \n",
      " In integer: 4020262153119643782837989383967985752122808315360222786683360755567309839741158713029944769305612277411645\n",
      "{-2: 9913043, 0: 10051064, 1: 10110880, 2: 10178451, 3: 10239092, 4: 10256163, 5: 10311743, 6: 10428057, 7: 10459335, 8: 10495495, 9: 10621710, 10: 10645813, 11: 10700220, 12: 10708006, 13: 10738547, 14: 10810050, 15: 10847584, 16: 10957410, 17: 10964188, 18: 11365368, 19: 11588596, 20: 11667110, 21: 11763668, 22: 11885383, 23: 12053585, 24: 12113758, 25: 12161483, 26: 12207861, 27: 12220718, 28: 12228678, 29: 12411484, 30: 12880615, 31: 12908743, 32: 12953385, 33: 13090980, 34: 13115331, 35: 13178136, 36: 13229076, 37: 13242460, 38: 13330733, 39: 13419802, 40: 13445220, 41: 13490312, 42: 13636489, 43: 13677650, 44: 13759948, 45: 13869191, 46: 13873290, 47: 13978160, 48: 13999815, 49: 14003727, 50: 14206181, 51: 14300211, 52: 14348370, 53: 14447938, 54: 14490267, 55: 14532391, 56: 14579174, 57: 14608709, 58: 14629144, 59: 14836263, 60: 14869055, 61: 14987140, 62: 15004161, 63: 15060946, 64: 15097465, 65: 15117359, 66: 15230501, 67: 15315763, 68: 15362959, 69: 15444120, 70: 15715255, 71: 15783505, 72: 15923727, 73: 16220423, 74: 16449773, 75: 16516335, 76: 16617270, 77: 16630217, 78: 16822442, 79: 16884121, 80: 17049015, 81: 17124478, 82: 17177288, 83: 17268477, 84: 17556604, 85: 17697882, 86: 17989391, 87: 17997012, 88: 18026941, 89: 18084151, 90: 18134712, 91: 18164559, 92: 18170021, 93: 18425234, 94: 18474629, 95: 18694294, 96: 18753691, 97: 18770967, 98: 18842916, 99: 18885576, 100: 18941096, 101: 18989692, 102: 19090878, 103: 19189268, 104: 19195352, 105: 19299643, 106: 19375230, 107: 19520442, 108: 19566562, 109: 19646520, 110: 19741924, 111: 19876868, 112: 20017480, 113: 20186726, 114: 20353394, 115: 20417394, 116: 20423880, 117: 20601169, 118: 20616151, 119: 20701944, 120: 20760777, 121: 20922159, 122: 20935212, 123: 20949093, 124: 21154015, 125: 21552822, 126: 21624175, 127: 21766390, 128: 21803174, 129: 21872065, 130: 21888611, 131: 21995049, 132: 22030451, 133: 22076871, 134: 22106706, 135: 22182362, 136: 22233998, 137: 22328802, 138: 22470632, 139: 22675573, 140: 22706844, 141: 22804188, 142: 22905731, 143: 23179616, 144: 23285041, 145: 23325386, 146: 23385643, 147: 23523728, 148: 23540087, 149: 23549793, 150: 23600049, 151: 23633797, 152: 23680677, 153: 23688318, 154: 23748647, 155: 23815899, 156: 23934509, 157: 24069123, 158: 24232237, 159: 24337832, 160: 24504358, 161: 24528725, 162: 24644451, 163: 24795033, 164: 24821599, 165: 24892030, 166: 24976881, 167: 25008933, 168: 25115710, 169: 25248773, 170: 25334079, 171: 25446567, 172: 25525499, 173: 25576794, 174: 25783554, 175: 25951792, 176: 26200278, 177: 26223148, 178: 26388402, 179: 26492103, 180: 26569119, 181: 26583230, 182: 26788597, 183: 26813641, 184: 27046868, 185: 27300507, 186: 27359496, 187: 27469521, 188: 27511823, 189: 27649726, 190: 27779031, 191: 27856488, 192: 27914552, 193: 28297357, 194: 28393765, 195: 28420691, 196: 28507066, 197: 28556627, 198: 28630342, 199: 28638909, 200: 28738167, 201: 28784011, 202: 29011573, 203: 29261974, 204: 29305152, 205: 29431268, 206: 29536505, 207: 29779720, 208: 29836311, 209: 29913437, 210: 29937843, 211: 30064936, 212: 30149096, 213: 30296791, 214: 30389757, 215: 30401307, 216: 30413833, 217: 30466770, 218: 30562752, 219: 30660245, 220: 30765812, 221: 30871825, 222: 30947139, 223: 31314262, 224: 31615197, 225: 31666910, 226: 31786626, 227: 31831851, 228: 31837200, 229: 31864861, 230: 32016039, 231: 32340647, 232: 32431008, 233: 32476996, 234: 32559869, 235: 32583906, 236: 32645203, 237: 32742412, 238: 32765761, 239: 32797269, 240: 32866907, 241: 33005106, 242: 33095294, 243: 33107600, 244: 33231184, 245: 33316975, 246: 33415852, 247: 33475824, 248: 33648479, 249: 33703614, 250: 33723953, 251: 33875088, 252: 33996506, 253: 34084541, 254: 34220365, 255: 34282105}\n"
     ]
    }
   ],
   "source": [
    "print(f'Key Display\\n In string: {cipher.generate_key().decode()} \\n In Hex: {cipher.generate_key().hex()} \\n In integer: {int(cipher.generate_key().hex(), base=16)}')\n",
    "print(OPE_ciphers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encrypted: Sequential: New FSM Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    \n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print (\"{}{}:if ({} <= {})\".format(indent, node, name, OPE_ciphers[int(round(threshold,3))]))\n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print (\"{}{}:else \".format(indent, node))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print (\"{} Label<={};\".format(indent, OPE_ciphers[np.argmax(tree_.value[node][0],axis=0)]))\n",
    "\n",
    "    recurse(0, 1)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['Encrypted_pixels['+str(i)+']' for i in cols]\n",
    "class_names = [str(OPE_ciphers[i]) for i in dt_clf.classes_]\n",
    "tree_to_code(dt_clf, features)\n",
    "\n",
    "with open('verilog_newFSM_enc.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(data_towrite):\n",
    "    with open('verilog_file_enc.v', 'a', encoding='utf-8') as file:\n",
    "        file.writelines(data_towrite)\n",
    "        file.close()\n",
    "        \n",
    "def write_line_file(data_towrite, line_num):\n",
    "    with open('verilog_file_enc.v', 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    file_content[line_num] = file_content[line_num].replace('\\n','') + ' ' + data_towrite + '\\n'  \n",
    "    with open('verilog_file_enc.v', 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "        \n",
    "def update_stateformat_file():\n",
    "    with open('verilog_file_enc.v', 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    for line_num,line in enumerate(file_content):\n",
    "        if 'if' in line:\n",
    "            file_content[line_num] = '16\\'d' + file_content[line_num].strip() + ' \\n'  \n",
    "    with open('verilog_file_enc.v', 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "        \n",
    "def search_content_file(word):\n",
    "    with open('verilog_file_enc.v', 'r') as file:\n",
    "        file_content = file.readlines()\n",
    "        for line_num,line in enumerate(file_content):\n",
    "            if word in line:\n",
    "                return(line_num)\n",
    "        return(\"content doesn't exists.\")\n",
    "        \n",
    "def clear_file():\n",
    "    with open('verilog_file_enc.v', 'w', encoding='utf-8') as file:\n",
    "        pass\n",
    "        file.close()\n",
    "\n",
    "import itertools\n",
    "with open('verilog_newFSM_enc.txt', 'r') as f:\n",
    "    tree_verilog = f.read()\n",
    "    f.close()\n",
    "\n",
    "clear_file()\n",
    "line_num = 0\n",
    "else_state = 0\n",
    "else_nextif_state = 0\n",
    "curr_line,next_line = itertools.tee(tree_verilog.split('\\n'))\n",
    "next(next_line, None)\n",
    "for i,j in list(zip(curr_line,next_line)):\n",
    "    if 'Label' in i:\n",
    "        pass\n",
    "        #write_file(f'  begin {i.strip()} state<=0;ml_inference_completed<=1; end \\n')\n",
    "    elif 'else' in i and 'Label' in j:\n",
    "        else_state = i.strip().split(':')[0]\n",
    "        line_num = search_content_file(' '+str(else_state)+':if' )\n",
    "        write_line_file(f'\\n       else begin {j.strip()} state<=0;ml_inference_completed<=1; end ', line_num)\n",
    "        #write_file(f'   {i.strip().split(\":\")[-1]} ')\n",
    "    elif 'else' in i and 'if' in j:\n",
    "        else_state = i.strip().split(':')[0]\n",
    "        else_nextif_state = j.strip().split(':')[0]\n",
    "        line_num = search_content_file(' '+str(else_state)+':if' )\n",
    "        write_line_file(f'else begin state<={else_nextif_state}; end ', line_num)\n",
    "    elif 'if' in i and 'Label' in j:\n",
    "        write_file(f'\\n {i.strip()} begin {j.strip()} state<=0;ml_inference_completed<=1; end ')\n",
    "    elif 'if' in i and 'if' in j:\n",
    "        write_file(f'\\n {i.strip()} begin state<={j.strip().split(\":\")[0]}; end \\n ')  \n",
    "update_stateformat_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the number of \"if\", \"else\" and \"Label\" in verilog with decision tree architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of \"if\" statements 252.\n",
      "Number of \"else\" statements 252.\n",
      "Number of \"label\" statements 253.\n"
     ]
    }
   ],
   "source": [
    "#verifying that the number of \"if\" statements is one less than the number of nodes.\n",
    "file1 = open('verilog_file_enc.v', 'r')\n",
    "contents = file1.readlines()\n",
    "counter_if =0\n",
    "for line in contents:\n",
    "    if 'if' in line:\n",
    "        counter_if = counter_if+1\n",
    "print('Number of \"if\" statements {}.'.format(counter_if))\n",
    "\n",
    "#verifying that the number of \"else\" statements is one less than the number of leaves.\n",
    "file1 = open('verilog_file_enc.v', 'r')\n",
    "contents = file1.readlines()\n",
    "counter_else =0\n",
    "for line in contents:\n",
    "    if 'else' in line:\n",
    "        counter_else = counter_else+1\n",
    "print('Number of \"else\" statements {}.'.format(counter_else))\n",
    "\n",
    "#verifying that the number of \"Label\" statements is equal to the number of leaves.\n",
    "file1 = open('verilog_file_enc.v', 'r')\n",
    "contents = file1.readlines()\n",
    "counter_return =0\n",
    "for line in contents:\n",
    "    if 'Label' in line:\n",
    "        counter_return = counter_return+1\n",
    "print('Number of \"label\" statements {}.'.format(counter_return))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
